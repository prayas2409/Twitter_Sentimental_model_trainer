{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                            \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.vegas-viz::vegas:0.3.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.vegas-viz::vegas-spark:0.3.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import $ivy.`org.vegas-viz::vegas:0.3.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-core:2.4.3`\n",
    "import $ivy.`org.apache.spark::spark-sql:2.4.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.data.External._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.render.WindowRenderer._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.sparkExt._\u001b[39m"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vegas.data.External._\n",
    "import org.apache.spark.sql._\n",
    "import vegas._\n",
    "import vegas.render.WindowRenderer._\n",
    "import vegas.sparkExt._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <iframe id=\"frame-vegas-65347f6f-26d3-47d4-aeba-9e9c3c04803c\" sandbox=\"allow-scripts allow-same-origin\" style=\"border: none; width: 100%\" srcdoc=\"&lt;html&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/d3/3.5.17/d3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega/2.6.3/vega.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega-lite/1.2.0/vega-lite.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://vega.github.io/vega-editor/vendor/vega-embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "  &lt;/head&gt;\n",
       "  &lt;body&gt;\n",
       " &lt;div id='vegas-65347f6f-26d3-47d4-aeba-9e9c3c04803c'&gt;&lt;/div&gt;\n",
       " &lt;script&gt;\n",
       "   var embedSpec = {\n",
       "     mode: &quot;vega-lite&quot;,\n",
       "     spec: {\n",
       "  &quot;mark&quot; : &quot;bar&quot;,\n",
       "  &quot;encoding&quot; : {\n",
       "    &quot;x&quot; : {\n",
       "      &quot;field&quot; : &quot;country&quot;,\n",
       "      &quot;type&quot; : &quot;nominal&quot;\n",
       "    },\n",
       "    &quot;y&quot; : {\n",
       "      &quot;field&quot; : &quot;population&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;description&quot; : &quot;Country Pop&quot;,\n",
       "  &quot;data&quot; : {\n",
       "    &quot;values&quot; : [\n",
       "      {\n",
       "        &quot;country&quot; : &quot;USA&quot;,\n",
       "        &quot;population&quot; : 314\n",
       "      },\n",
       "      {\n",
       "        &quot;country&quot; : &quot;UK&quot;,\n",
       "        &quot;population&quot; : 64\n",
       "      },\n",
       "      {\n",
       "        &quot;country&quot; : &quot;DK&quot;,\n",
       "        &quot;population&quot; : 80\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "}\n",
       "   }\n",
       "   vg.embed(&quot;#vegas-65347f6f-26d3-47d4-aeba-9e9c3c04803c&quot;, embedSpec, function(error, result) {});\n",
       " &lt;/script&gt;\n",
       "\n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\"></iframe>\n",
       "  <script>\n",
       "    (function() {\n",
       "      function resizeIFrame(el, k) {\n",
       "        var height = el.contentWindow.document.body.scrollHeight || '400'; // Fallback in case of no scroll height\n",
       "        el.style.height = height + 'px';\n",
       "        if (k <= 10) { setTimeout(function() { resizeIFrame(el, k+1) }, 1000 + (k * 250)) };\n",
       "      }\n",
       "      resizeIFrame(document.querySelector('#frame-vegas-65347f6f-26d3-47d4-aeba-9e9c3c04803c'), 1);\n",
       "    })(); // IIFE\n",
       "  </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mplot\u001b[39m: \u001b[32mDSL\u001b[39m.\u001b[32mExtendedUnitSpecBuilder\u001b[39m = \u001b[33mExtendedUnitSpecBuilder\u001b[39m(\n",
       "  \u001b[33mExtendedUnitSpec\u001b[39m(\n",
       "    \u001b[32mNone\u001b[39m,\n",
       "    \u001b[32mNone\u001b[39m,\n",
       "    Bar,\n",
       "    \u001b[33mSome\u001b[39m(\n",
       "      \u001b[33mEncoding\u001b[39m(\n",
       "        \u001b[32mNone\u001b[39m,\n",
       "        \u001b[32mNone\u001b[39m,\n",
       "        \u001b[33mSome\u001b[39m(\n",
       "          \u001b[33mPositionChannelDef\u001b[39m(\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[33mSome\u001b[39m(\u001b[32m\"country\"\u001b[39m),\n",
       "            \u001b[33mSome\u001b[39m(Nominal),\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m\n",
       "          )\n",
       "        ),\n",
       "        \u001b[33mSome\u001b[39m(\n",
       "          \u001b[33mPositionChannelDef\u001b[39m(\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[33mSome\u001b[39m(\u001b[32m\"population\"\u001b[39m),\n",
       "            \u001b[33mSome\u001b[39m(Quantitative),\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m,\n",
       "            \u001b[32mNone\u001b[39m\n",
       "          )\n",
       "        ),\n",
       "        \u001b[32mNone\u001b[39m,\n",
       "        \u001b[32mNone\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Vegas(\"Country Pop\").\n",
    "  withData(\n",
    "    Seq(\n",
    "      Map(\"country\" -> \"USA\", \"population\" -> 314),\n",
    "      Map(\"country\" -> \"UK\", \"population\" -> 64),\n",
    "      Map(\"country\" -> \"DK\", \"population\" -> 80)\n",
    "    )\n",
    "  ).\n",
    "  encodeX(\"country\", Nom).\n",
    "  encodeY(\"population\", Quant).\n",
    "  mark(Bar)\n",
    "\n",
    "plot.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "// Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <iframe id=\"frame-vegas-ecce7f67-194e-419c-bb10-c3929024c812\" sandbox=\"allow-scripts allow-same-origin\" style=\"border: none; width: 100%\" srcdoc=\"&lt;html&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/d3/3.5.17/d3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega/2.6.3/vega.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega-lite/1.2.0/vega-lite.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://vega.github.io/vega-editor/vendor/vega-embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "  &lt;/head&gt;\n",
       "  &lt;body&gt;\n",
       " &lt;div id='vegas-ecce7f67-194e-419c-bb10-c3929024c812'&gt;&lt;/div&gt;\n",
       " &lt;script&gt;\n",
       "   var embedSpec = {\n",
       "     mode: &quot;vega-lite&quot;,\n",
       "     spec: {\n",
       "  &quot;width&quot; : 400.0,\n",
       "  &quot;height&quot; : 300.0,\n",
       "  &quot;mark&quot; : &quot;area&quot;,\n",
       "  &quot;encoding&quot; : {\n",
       "    &quot;x&quot; : {\n",
       "      &quot;field&quot; : &quot;date&quot;,\n",
       "      &quot;type&quot; : &quot;ordinal&quot;\n",
       "    },\n",
       "    &quot;y&quot; : {\n",
       "      &quot;field&quot; : &quot;open&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;description&quot; : &quot;dataframe predictions&quot;,\n",
       "  &quot;data&quot; : {\n",
       "    &quot;format&quot; : {\n",
       "      &quot;type&quot; : &quot;csv&quot;\n",
       "    },\n",
       "    &quot;url&quot; : &quot;https://raw.githubusercontent.com/prayas2409/Stockpricepython/master/Data/df1.csv&quot;\n",
       "  }\n",
       "}\n",
       "   }\n",
       "   vg.embed(&quot;#vegas-ecce7f67-194e-419c-bb10-c3929024c812&quot;, embedSpec, function(error, result) {});\n",
       " &lt;/script&gt;\n",
       "\n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\"></iframe>\n",
       "  <script>\n",
       "    (function() {\n",
       "      function resizeIFrame(el, k) {\n",
       "        var height = el.contentWindow.document.body.scrollHeight || '400'; // Fallback in case of no scroll height\n",
       "        el.style.height = height + 'px';\n",
       "        if (k <= 10) { setTimeout(function() { resizeIFrame(el, k+1) }, 1000 + (k * 250)) };\n",
       "      }\n",
       "      resizeIFrame(document.querySelector('#frame-vegas-ecce7f67-194e-419c-bb10-c3929024c812'), 1);\n",
       "    })(); // IIFE\n",
       "  </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vegas(\"dataframe predictions\", width=400, height=300)\n",
    ".withURL(\"https://raw.githubusercontent.com/prayas2409/Stockpricepython/master/Data/df1.csv\",formatType=DataFormat.Csv)\n",
    ".mark(Area)\n",
    ".encodeX(\"date\", Ordinal)\n",
    ".encodeY(\"open\", Quantitative)\n",
    ".show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <iframe id=\"frame-vegas-ab4645fe-b470-4bf0-8d58-c95f70b8759d\" sandbox=\"allow-scripts allow-same-origin\" style=\"border: none; width: 100%\" srcdoc=\"&lt;html&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/d3/3.5.17/d3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega/2.6.3/vega.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega-lite/1.2.0/vega-lite.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://vega.github.io/vega-editor/vendor/vega-embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "  &lt;/head&gt;\n",
       "  &lt;body&gt;\n",
       " &lt;div id='vegas-ab4645fe-b470-4bf0-8d58-c95f70b8759d'&gt;&lt;/div&gt;\n",
       " &lt;script&gt;\n",
       "   var embedSpec = {\n",
       "     mode: &quot;vega-lite&quot;,\n",
       "     spec: {\n",
       "  &quot;width&quot; : 400.0,\n",
       "  &quot;height&quot; : 300.0,\n",
       "  &quot;mark&quot; : &quot;bar&quot;,\n",
       "  &quot;encoding&quot; : {\n",
       "    &quot;x&quot; : {\n",
       "      &quot;field&quot; : &quot;year&quot;,\n",
       "      &quot;type&quot; : &quot;ordinal&quot;\n",
       "    },\n",
       "    &quot;y&quot; : {\n",
       "      &quot;field&quot; : &quot;age&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;description&quot; : &quot;dataframe predictions&quot;,\n",
       "  &quot;data&quot; : {\n",
       "    &quot;url&quot; : &quot;https://vega.github.io/vega-editor/app/data/population.json&quot;\n",
       "  }\n",
       "}\n",
       "   }\n",
       "   vg.embed(&quot;#vegas-ab4645fe-b470-4bf0-8d58-c95f70b8759d&quot;, embedSpec, function(error, result) {});\n",
       " &lt;/script&gt;\n",
       "\n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\"></iframe>\n",
       "  <script>\n",
       "    (function() {\n",
       "      function resizeIFrame(el, k) {\n",
       "        var height = el.contentWindow.document.body.scrollHeight || '400'; // Fallback in case of no scroll height\n",
       "        el.style.height = height + 'px';\n",
       "        if (k <= 10) { setTimeout(function() { resizeIFrame(el, k+1) }, 1000 + (k * 250)) };\n",
       "      }\n",
       "      resizeIFrame(document.querySelector('#frame-vegas-ab4645fe-b470-4bf0-8d58-c95f70b8759d'), 1);\n",
       "    })(); // IIFE\n",
       "  </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vegas(\"dataframe predictions\", width=400, height=300)\n",
    "// .withURL(\"https://raw.githubusercontent.com/prayas2409/Stockpricepython/master/Data/df1.csv\",formatType=DataFormat.Csv)\n",
    " .withURL(\"https://vega.github.io/vega-editor/app/data/population.json\")\n",
    ".mark(Bar)\n",
    ".encodeX(\"year\", Ordinal)\n",
    ".encodeY(\"age\", Quantitative)\n",
    ".show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "19/07/12 16:35:09 WARN Utils: Your hostname, admin1-desktop resolves to a loopback address: 127.0.1.1; using 192.168.0.72 instead (on interface enp1s0)\n",
      "19/07/12 16:35:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "19/07/12 16:35:19 INFO SparkContext: Running Spark version 2.4.3\n",
      "19/07/12 16:35:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "19/07/12 16:35:21 INFO SparkContext: Submitted application: stockmarkets\n",
      "19/07/12 16:35:21 INFO SecurityManager: Changing view acls to: admin1\n",
      "19/07/12 16:35:21 INFO SecurityManager: Changing modify acls to: admin1\n",
      "19/07/12 16:35:21 INFO SecurityManager: Changing view acls groups to: \n",
      "19/07/12 16:35:21 INFO SecurityManager: Changing modify acls groups to: \n",
      "19/07/12 16:35:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(admin1); groups with view permissions: Set(); users  with modify permissions: Set(admin1); groups with modify permissions: Set()\n",
      "19/07/12 16:35:22 INFO Utils: Successfully started service 'sparkDriver' on port 41599.\n",
      "19/07/12 16:35:22 INFO SparkEnv: Registering MapOutputTracker\n",
      "19/07/12 16:35:22 INFO SparkEnv: Registering BlockManagerMaster\n",
      "19/07/12 16:35:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "19/07/12 16:35:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "19/07/12 16:35:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-563ab5fe-2995-4513-a06a-cacf96dd7382\n",
      "19/07/12 16:35:22 INFO MemoryStore: MemoryStore started with capacity 1005.6 MB\n",
      "19/07/12 16:35:23 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "19/07/12 16:35:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "19/07/12 16:35:23 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.72:4040\n",
      "19/07/12 16:35:23 INFO Executor: Starting executor ID driver on host localhost\n",
      "19/07/12 16:35:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37675.\n",
      "19/07/12 16:35:24 INFO NettyBlockTransferService: Server created on 192.168.0.72:37675\n",
      "19/07/12 16:35:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "19/07/12 16:35:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.72, 37675, None)\n",
      "19/07/12 16:35:24 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.72:37675 with 1005.6 MB RAM, BlockManagerId(driver, 192.168.0.72, 37675, None)\n",
      "19/07/12 16:35:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.72, 37675, None)\n",
      "19/07/12 16:35:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.72, 37675, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@50c2262e"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().appName(\"stockmarkets\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/07/12 16:35:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/admin1/IdeaProjects/StockPricePrediction/src/main/Vegas%20visualization/spark-warehouse').\n",
      "19/07/12 16:35:25 INFO SharedState: Warehouse path is 'file:/home/admin1/IdeaProjects/StockPricePrediction/src/main/Vegas%20visualization/spark-warehouse'.\n",
      "19/07/12 16:35:26 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\n",
      "19/07/12 16:35:30 INFO FileSourceStrategy: Pruning directories with: \n",
      "19/07/12 16:35:30 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\n",
      "19/07/12 16:35:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "19/07/12 16:35:30 INFO FileSourceScanExec: Pushed Filters: \n",
      "19/07/12 16:35:31 INFO CodeGenerator: Code generated in 331.800632 ms\n",
      "19/07/12 16:35:31 INFO CodeGenerator: Code generated in 16.99382 ms\n",
      "19/07/12 16:35:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 113.0 KB, free 1005.5 MB)\n",
      "19/07/12 16:35:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1005.5 MB)\n",
      "19/07/12 16:35:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.72:37675 (size: 20.7 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:31 INFO SparkContext: Created broadcast 0 from load at cmd19.sc:1\n",
      "19/07/12 16:35:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "19/07/12 16:35:32 INFO SparkContext: Starting job: load at cmd19.sc:1\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Got job 0 (load at cmd19.sc:1) with 1 output partitions\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Final stage: ResultStage 0 (load at cmd19.sc:1)\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Missing parents: List()\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at cmd19.sc:1), which has no missing parents\n",
      "19/07/12 16:35:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 1005.5 MB)\n",
      "19/07/12 16:35:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1005.5 MB)\n",
      "19/07/12 16:35:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.72:37675 (size: 4.5 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at cmd19.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "19/07/12 16:35:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks\n",
      "19/07/12 16:35:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8375 bytes)\n",
      "19/07/12 16:35:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "19/07/12 16:35:32 INFO FileScanRDD: Reading File path: file:///home/admin1/IdeaProjects/StockPricePrediction/src/main/Vegas%20visualization/Data/df1.csv, range: 0-274, partition values: [empty row]\n",
      "19/07/12 16:35:32 INFO CodeGenerator: Code generated in 33.436947 ms\n",
      "19/07/12 16:35:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1291 bytes result sent to driver\n",
      "19/07/12 16:35:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 415 ms on localhost (executor driver) (1/1)\n",
      "19/07/12 16:35:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "19/07/12 16:35:32 INFO DAGScheduler: ResultStage 0 (load at cmd19.sc:1) finished in 0.629 s\n",
      "19/07/12 16:35:32 INFO DAGScheduler: Job 0 finished: load at cmd19.sc:1, took 0.825708 s\n",
      "19/07/12 16:35:33 INFO FileSourceStrategy: Pruning directories with: \n",
      "19/07/12 16:35:33 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "19/07/12 16:35:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "19/07/12 16:35:33 INFO FileSourceScanExec: Pushed Filters: \n",
      "19/07/12 16:35:33 INFO CodeGenerator: Code generated in 6.711194 ms\n",
      "19/07/12 16:35:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 113.0 KB, free 1005.3 MB)\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 27\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 20\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 7\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 28\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 10\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 24\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 14\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 12\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 15\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 17\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 8\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 29\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 13\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 22\n",
      "19/07/12 16:35:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1005.3 MB)\n",
      "19/07/12 16:35:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.72:37675 (size: 20.7 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:33 INFO SparkContext: Created broadcast 2 from load at cmd19.sc:1\n",
      "19/07/12 16:35:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "19/07/12 16:35:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.72:37675 in memory (size: 4.5 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 6\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 21\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 23\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 9\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 11\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 16\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 19\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 26\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 30\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 18\n",
      "19/07/12 16:35:33 INFO ContextCleaner: Cleaned accumulator 25\n",
      "19/07/12 16:35:33 INFO SparkContext: Starting job: load at cmd19.sc:1\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Got job 1 (load at cmd19.sc:1) with 2 output partitions\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Final stage: ResultStage 1 (load at cmd19.sc:1)\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Parents of final stage: List()\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Missing parents: List()\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at load at cmd19.sc:1), which has no missing parents\n",
      "19/07/12 16:35:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.2 KB, free 1005.3 MB)\n",
      "19/07/12 16:35:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.2 KB, free 1005.3 MB)\n",
      "19/07/12 16:35:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.72:37675 (size: 7.2 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at load at cmd19.sc:1) (first 15 tasks are for partitions Vector(0, 1))\n",
      "19/07/12 16:35:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks\n",
      "19/07/12 16:35:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8375 bytes)\n",
      "19/07/12 16:35:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 8375 bytes)\n",
      "19/07/12 16:35:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "19/07/12 16:35:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "19/07/12 16:35:33 INFO FileScanRDD: Reading File path: file:///home/admin1/IdeaProjects/StockPricePrediction/src/main/Vegas%20visualization/Data/df1.csv, range: 0-274, partition values: [empty row]\n",
      "19/07/12 16:35:33 INFO FileScanRDD: Reading File path: file:///home/admin1/IdeaProjects/StockPricePrediction/src/main/Vegas%20visualization/Data/df1.csv, range: 0-274, partition values: [empty row]\n",
      "19/07/12 16:35:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1637 bytes result sent to driver\n",
      "19/07/12 16:35:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 98 ms on localhost (executor driver) (1/2)\n",
      "19/07/12 16:35:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1594 bytes result sent to driver\n",
      "19/07/12 16:35:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 108 ms on localhost (executor driver) (2/2)\n",
      "19/07/12 16:35:33 INFO DAGScheduler: ResultStage 1 (load at cmd19.sc:1) finished in 0.135 s\n",
      "19/07/12 16:35:33 INFO DAGScheduler: Job 1 finished: load at cmd19.sc:1, took 0.139383 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date: string, close: double ... 4 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").options(Map(\"inferSchema\"->\"true\",\"header\" -> \"true\")).load(\"Data/df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/07/12 16:35:37 INFO FileSourceStrategy: Pruning directories with: \n",
      "19/07/12 16:35:37 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "19/07/12 16:35:37 INFO FileSourceStrategy: Output Data Schema: struct<date: string, close: double, volume: int, open: double, high: double ... 1 more field>\n",
      "19/07/12 16:35:37 INFO FileSourceScanExec: Pushed Filters: \n",
      "19/07/12 16:35:37 INFO CodeGenerator: Code generated in 13.396239 ms\n",
      "19/07/12 16:35:37 INFO CodeGenerator: Code generated in 24.354184 ms\n",
      "19/07/12 16:35:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 113.0 KB, free 1005.2 MB)\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 46\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 57\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 55\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 56\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 58\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 44\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 40\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 60\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 45\n",
      "19/07/12 16:35:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1005.2 MB)\n",
      "19/07/12 16:35:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.72:37675 (size: 20.7 KB, free: 1005.5 MB)\n",
      "19/07/12 16:35:37 INFO SparkContext: Created broadcast 4 from show at cmd20.sc:1\n",
      "19/07/12 16:35:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "19/07/12 16:35:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.72:37675 in memory (size: 7.2 KB, free: 1005.5 MB)\n",
      "19/07/12 16:35:37 INFO SparkContext: Starting job: show at cmd20.sc:1\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Got job 2 (show at cmd20.sc:1) with 1 output partitions\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Final stage: ResultStage 2 (show at cmd20.sc:1)\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Parents of final stage: List()\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Missing parents: List()\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at show at cmd20.sc:1), which has no missing parents\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 42\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 47\n",
      "19/07/12 16:35:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.0.72:37675 in memory (size: 20.7 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.2 KB, free 1005.3 MB)\n",
      "19/07/12 16:35:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 1005.3 MB)\n",
      "19/07/12 16:35:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.72:37675 (size: 6.5 KB, free: 1005.6 MB)\n",
      "19/07/12 16:35:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 54\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 53\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 39\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 49\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 51\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 59\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 48\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 36\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 37\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 41\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 50\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 52\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 38\n",
      "19/07/12 16:35:37 INFO ContextCleaner: Cleaned accumulator 43\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at cmd20.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "19/07/12 16:35:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks\n",
      "19/07/12 16:35:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8375 bytes)\n",
      "19/07/12 16:35:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)\n",
      "19/07/12 16:35:37 INFO FileScanRDD: Reading File path: file:///home/admin1/IdeaProjects/StockPricePrediction/src/main/Vegas%20visualization/Data/df1.csv, range: 0-274, partition values: [empty row]\n",
      "19/07/12 16:35:37 INFO CodeGenerator: Code generated in 38.864475 ms\n",
      "19/07/12 16:35:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 1504 bytes result sent to driver\n",
      "19/07/12 16:35:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 165 ms on localhost (executor driver) (1/1)\n",
      "19/07/12 16:35:37 INFO DAGScheduler: ResultStage 2 (show at cmd20.sc:1) finished in 0.296 s\n",
      "19/07/12 16:35:37 INFO DAGScheduler: Job 2 finished: show at cmd20.sc:1, took 0.300262 s\n",
      "19/07/12 16:35:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+-------+\n",
      "|      date|  close| volume|   open|   high|    low|\n",
      "+----------+-------+-------+-------+-------+-------+\n",
      "|2019/06/28|1080.91|1693450|1076.39| 1081.0|1073.37|\n",
      "|2019/06/27|1076.01|1004477| 1084.0| 1087.1|1075.29|\n",
      "|2019/06/26| 1079.8|1810869| 1086.5|1092.97|1072.24|\n",
      "|2019/06/25|1086.35|1546913|1112.66|1114.35| 1083.8|\n",
      "|2019/06/24|1115.52|1395696|1119.61| 1122.0|1111.01|\n",
      "+----------+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/07/12 17:09:59 INFO FileSourceStrategy: Pruning directories with: \n",
      "19/07/12 17:09:59 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "19/07/12 17:09:59 INFO FileSourceStrategy: Output Data Schema: struct<>\n",
      "19/07/12 17:09:59 INFO FileSourceScanExec: Pushed Filters: \n",
      "19/07/12 17:09:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 113.0 KB, free 1005.5 MB)\n",
      "19/07/12 17:09:59 INFO ContextCleaner: Cleaned accumulator 127\n",
      "19/07/12 17:09:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1005.5 MB)\n",
      "19/07/12 17:09:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.0.72:37675 (size: 20.7 KB, free: 1005.6 MB)\n",
      "19/07/12 17:09:59 INFO SparkContext: Created broadcast 8 from count at package.scala:14\n",
      "19/07/12 17:09:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mjava.lang.IllegalArgumentException: Unsupported class file major version 55\u001b[39m\n  org.apache.xbean.asm6.ClassReader.<init>(\u001b[32mClassReader.java\u001b[39m:\u001b[32m166\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.<init>(\u001b[32mClassReader.java\u001b[39m:\u001b[32m148\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.<init>(\u001b[32mClassReader.java\u001b[39m:\u001b[32m136\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.<init>(\u001b[32mClassReader.java\u001b[39m:\u001b[32m237\u001b[39m)\n  org.apache.spark.util.ClosureCleaner$.getClassReader(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m49\u001b[39m)\n  org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m517\u001b[39m)\n  org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m500\u001b[39m)\n  scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(\u001b[32mTraversableLike.scala\u001b[39m:\u001b[32m733\u001b[39m)\n  scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(\u001b[32mHashMap.scala\u001b[39m:\u001b[32m134\u001b[39m)\n  scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(\u001b[32mHashMap.scala\u001b[39m:\u001b[32m134\u001b[39m)\n  scala.collection.mutable.HashTable$class.foreachEntry(\u001b[32mHashTable.scala\u001b[39m:\u001b[32m236\u001b[39m)\n  scala.collection.mutable.HashMap.foreachEntry(\u001b[32mHashMap.scala\u001b[39m:\u001b[32m40\u001b[39m)\n  scala.collection.mutable.HashMap$$anon$1.foreach(\u001b[32mHashMap.scala\u001b[39m:\u001b[32m134\u001b[39m)\n  scala.collection.TraversableLike$WithFilter.foreach(\u001b[32mTraversableLike.scala\u001b[39m:\u001b[32m732\u001b[39m)\n  org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m500\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.readCode(\u001b[32mClassReader.java\u001b[39m:\u001b[32m2175\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.readMethod(\u001b[32mClassReader.java\u001b[39m:\u001b[32m1238\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.accept(\u001b[32mClassReader.java\u001b[39m:\u001b[32m631\u001b[39m)\n  org.apache.xbean.asm6.ClassReader.accept(\u001b[32mClassReader.java\u001b[39m:\u001b[32m355\u001b[39m)\n  org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m307\u001b[39m)\n  org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m306\u001b[39m)\n  scala.collection.immutable.List.foreach(\u001b[32mList.scala\u001b[39m:\u001b[32m392\u001b[39m)\n  org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m306\u001b[39m)\n  org.apache.spark.util.ClosureCleaner$.clean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m162\u001b[39m)\n  org.apache.spark.SparkContext.clean(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2326\u001b[39m)\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2100\u001b[39m)\n  org.apache.spark.SparkContext.runJob(\u001b[32mSparkContext.scala\u001b[39m:\u001b[32m2126\u001b[39m)\n  org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(\u001b[32mRDD.scala\u001b[39m:\u001b[32m945\u001b[39m)\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m151\u001b[39m)\n  org.apache.spark.rdd.RDDOperationScope$.withScope(\u001b[32mRDDOperationScope.scala\u001b[39m:\u001b[32m112\u001b[39m)\n  org.apache.spark.rdd.RDD.withScope(\u001b[32mRDD.scala\u001b[39m:\u001b[32m363\u001b[39m)\n  org.apache.spark.rdd.RDD.collect(\u001b[32mRDD.scala\u001b[39m:\u001b[32m944\u001b[39m)\n  org.apache.spark.sql.execution.SparkPlan.executeCollect(\u001b[32mSparkPlan.scala\u001b[39m:\u001b[32m299\u001b[39m)\n  org.apache.spark.sql.Dataset$$anonfun$count$1.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m2830\u001b[39m)\n  org.apache.spark.sql.Dataset$$anonfun$count$1.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m2829\u001b[39m)\n  org.apache.spark.sql.Dataset$$anonfun$53.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m3364\u001b[39m)\n  org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(\u001b[32mSQLExecution.scala\u001b[39m:\u001b[32m78\u001b[39m)\n  org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(\u001b[32mSQLExecution.scala\u001b[39m:\u001b[32m125\u001b[39m)\n  org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(\u001b[32mSQLExecution.scala\u001b[39m:\u001b[32m73\u001b[39m)\n  org.apache.spark.sql.Dataset.withAction(\u001b[32mDataset.scala\u001b[39m:\u001b[32m3363\u001b[39m)\n  org.apache.spark.sql.Dataset.count(\u001b[32mDataset.scala\u001b[39m:\u001b[32m2829\u001b[39m)\n  vegas.sparkExt.package$VegasSpark.withDataFrame(\u001b[32mpackage.scala\u001b[39m:\u001b[32m14\u001b[39m)\n  ammonite.$sess.cmd40$Helper.<init>(\u001b[32mcmd40.sc\u001b[39m:\u001b[32m2\u001b[39m)\n  ammonite.$sess.cmd40$.<init>(\u001b[32mcmd40.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd40$.<clinit>(\u001b[32mcmd40.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "Vegas(\"A trellis scatterplot showing Horsepower and Miles per gallons, faceted by binned values of Acceleration.\").\n",
    "  withDataFrame(df:DataFrame).\n",
    "  mark(Point).\n",
    "  encodeX(\"open\", Quantitative).\n",
    "  encodeY(\"high\", Quantitative).\n",
    "  show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/07/12 17:02:21 INFO ContextCleaner: Cleaned accumulator 99\n",
      "19/07/12 17:02:21 INFO ContextCleaner: Cleaned accumulator 103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mPopulation\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/population.json\"\u001b[39m\n",
       "\u001b[36mCars\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/cars.json\"\u001b[39m\n",
       "\u001b[36mUnemployment\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/unemployment-across-industries.json\"\u001b[39m\n",
       "\u001b[36mMovies\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/movies.json\"\u001b[39m\n",
       "\u001b[36mBarley\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/barley.json\"\u001b[39m\n",
       "\u001b[36mStocks\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/stocks.csv\"\u001b[39m\n",
       "\u001b[36mGithub\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/github.csv\"\u001b[39m\n",
       "\u001b[36mAnscombe\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/anscombe.json\"\u001b[39m\n",
       "\u001b[36mSeattleWeather\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://vega.github.io/vega-editor/app/data/seattle-weather.csv\"\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Population = \"https://vega.github.io/vega-editor/app/data/population.json\"\n",
    "val Cars = \"https://vega.github.io/vega-editor/app/data/cars.json\"\n",
    "val Unemployment = \"https://vega.github.io/vega-editor/app/data/unemployment-across-industries.json\"\n",
    "val Movies = \"https://vega.github.io/vega-editor/app/data/movies.json\"\n",
    "val Barley = \"https://vega.github.io/vega-editor/app/data/barley.json\"\n",
    "val Stocks = \"https://vega.github.io/vega-editor/app/data/stocks.csv\"\n",
    "val Github = \"https://vega.github.io/vega-editor/app/data/github.csv\"\n",
    "val Anscombe = \"https://vega.github.io/vega-editor/app/data/anscombe.json\"\n",
    "val SeattleWeather = \"https://vega.github.io/vega-editor/app/data/seattle-weather.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <iframe id=\"frame-vegas-ac8a6057-6a11-49ea-9fe4-73d397f0e237\" sandbox=\"allow-scripts allow-same-origin\" style=\"border: none; width: 100%\" srcdoc=\"&lt;html&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/d3/3.5.17/d3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega/2.6.3/vega.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega-lite/1.2.0/vega-lite.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://vega.github.io/vega-editor/vendor/vega-embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "  &lt;/head&gt;\n",
       "  &lt;body&gt;\n",
       " &lt;div id='vegas-ac8a6057-6a11-49ea-9fe4-73d397f0e237'&gt;&lt;/div&gt;\n",
       " &lt;script&gt;\n",
       "   var embedSpec = {\n",
       "     mode: &quot;vega-lite&quot;,\n",
       "     spec: {\n",
       "  &quot;width&quot; : 800.0,\n",
       "  &quot;height&quot; : 600.0,\n",
       "  &quot;mark&quot; : &quot;point&quot;,\n",
       "  &quot;encoding&quot; : {\n",
       "    &quot;x&quot; : {\n",
       "      &quot;field&quot; : &quot;Horsepower&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    },\n",
       "    &quot;y&quot; : {\n",
       "      &quot;field&quot; : &quot;Miles_per_Gallon&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    },\n",
       "    &quot;color&quot; : {\n",
       "      &quot;field&quot; : &quot;Acceleration&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;,\n",
       "      &quot;bin&quot; : {\n",
       "        &quot;maxbins&quot; : 5.0\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  &quot;description&quot; : &quot;Sample Scatterplot&quot;,\n",
       "  &quot;data&quot; : {\n",
       "    &quot;url&quot; : &quot;https://vega.github.io/vega-editor/app/data/cars.json&quot;\n",
       "  }\n",
       "}\n",
       "   }\n",
       "   vg.embed(&quot;#vegas-ac8a6057-6a11-49ea-9fe4-73d397f0e237&quot;, embedSpec, function(error, result) {});\n",
       " &lt;/script&gt;\n",
       "\n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\"></iframe>\n",
       "  <script>\n",
       "    (function() {\n",
       "      function resizeIFrame(el, k) {\n",
       "        var height = el.contentWindow.document.body.scrollHeight || '400'; // Fallback in case of no scroll height\n",
       "        el.style.height = height + 'px';\n",
       "        if (k <= 10) { setTimeout(function() { resizeIFrame(el, k+1) }, 1000 + (k * 250)) };\n",
       "      }\n",
       "      resizeIFrame(document.querySelector('#frame-vegas-ac8a6057-6a11-49ea-9fe4-73d397f0e237'), 1);\n",
       "    })(); // IIFE\n",
       "  </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vegas(\"Sample Scatterplot\", width=800, height=600)\n",
    "  .withURL(Cars)\n",
    "  .mark(Point)\n",
    "  .encodeX(\"Horsepower\", Quantitative)\n",
    "  .encodeY(\"Miles_per_Gallon\", Quantitative)\n",
    "  .encodeColor(field=\"Acceleration\", dataType=Quantitative, bin=Bin(maxbins=5.0))\n",
    "  .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <iframe id=\"frame-vegas-970f9eb2-610b-45ee-95f5-4557b5f764db\" sandbox=\"allow-scripts allow-same-origin\" style=\"border: none; width: 100%\" srcdoc=\"&lt;html&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/d3/3.5.17/d3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega/2.6.3/vega.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega-lite/1.2.0/vega-lite.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://vega.github.io/vega-editor/vendor/vega-embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "  &lt;/head&gt;\n",
       "  &lt;body&gt;\n",
       " &lt;div id='vegas-970f9eb2-610b-45ee-95f5-4557b5f764db'&gt;&lt;/div&gt;\n",
       " &lt;script&gt;\n",
       "   var embedSpec = {\n",
       "     mode: &quot;vega-lite&quot;,\n",
       "     spec: {\n",
       "  &quot;width&quot; : 800.0,\n",
       "  &quot;height&quot; : 600.0,\n",
       "  &quot;mark&quot; : &quot;point&quot;,\n",
       "  &quot;encoding&quot; : {\n",
       "    &quot;x&quot; : {\n",
       "      &quot;field&quot; : &quot;date&quot;,\n",
       "      &quot;type&quot; : &quot;temporal&quot;,\n",
       "      &quot;bin&quot; : {\n",
       "        &quot;maxbins&quot; : 10.0\n",
       "      }\n",
       "    },\n",
       "    &quot;y&quot; : {\n",
       "      &quot;field&quot; : &quot;price&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    },\n",
       "    &quot;color&quot; : {\n",
       "      &quot;legend&quot; : {\n",
       "        &quot;title&quot; : &quot;Stock Companies&quot;,\n",
       "        &quot;orient&quot; : &quot;left&quot;\n",
       "      },\n",
       "      &quot;field&quot; : &quot;symbol&quot;,\n",
       "      &quot;type&quot; : &quot;nominal&quot;\n",
       "    },\n",
       "    &quot;detail&quot; : {\n",
       "      &quot;field&quot; : &quot;symbol&quot;,\n",
       "      &quot;type&quot; : &quot;nominal&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;description&quot; : &quot;Sample Multi Series Line Chart&quot;,\n",
       "  &quot;data&quot; : {\n",
       "    &quot;format&quot; : {\n",
       "      &quot;type&quot; : &quot;csv&quot;\n",
       "    },\n",
       "    &quot;url&quot; : &quot;https://vega.github.io/vega-editor/app/data/stocks.csv&quot;\n",
       "  }\n",
       "}\n",
       "   }\n",
       "   vg.embed(&quot;#vegas-970f9eb2-610b-45ee-95f5-4557b5f764db&quot;, embedSpec, function(error, result) {});\n",
       " &lt;/script&gt;\n",
       "\n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\"></iframe>\n",
       "  <script>\n",
       "    (function() {\n",
       "      function resizeIFrame(el, k) {\n",
       "        var height = el.contentWindow.document.body.scrollHeight || '400'; // Fallback in case of no scroll height\n",
       "        el.style.height = height + 'px';\n",
       "        if (k <= 10) { setTimeout(function() { resizeIFrame(el, k+1) }, 1000 + (k * 250)) };\n",
       "      }\n",
       "      resizeIFrame(document.querySelector('#frame-vegas-970f9eb2-610b-45ee-95f5-4557b5f764db'), 1);\n",
       "    })(); // IIFE\n",
       "  </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vegas(\"Sample Multi Series Line Chart\", width=800, height=600)\n",
    "    .withURL(Stocks, formatType=DataFormat.Csv)\n",
    "    .mark(Point)\n",
    "    .encodeX(\"date\", Temp,bin=Bin(maxbins=10.0))\n",
    "    .encodeY(\"price\", Quant)\n",
    "    .encodeColor(\n",
    "       field=\"symbol\",\n",
    "       dataType=Nominal,\n",
    "       legend=Legend(orient=\"left\", title=\"Stock Companies\"))\n",
    "    .encodeDetailFields(Field(field=\"symbol\", dataType=Nominal))\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
